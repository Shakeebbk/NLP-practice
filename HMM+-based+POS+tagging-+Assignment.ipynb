{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('treebank')\n",
    "# nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(nltk_data, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('promised', 'VERB'),\n",
       " ('stiffer', 'ADJ'),\n",
       " ('fines', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('though', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('size', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('penalties', 'NOUN'),\n",
       " ('sought', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('OSHA', 'NOUN'),\n",
       " ('have', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('rising', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('recent', 'ADJ'),\n",
       " ('years', 'NOUN'),\n",
       " ('even', 'ADV'),\n",
       " ('before', 'ADP'),\n",
       " ('he', 'PRON'),\n",
       " ('took', 'VERB'),\n",
       " ('office', 'NOUN'),\n",
       " ('this', 'DET'),\n",
       " ('year', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95668"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tags\n",
    "len(set([tag for word, tag in train_tagged_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set([tag for word, tag in train_tagged_words])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(iword, itag, train_bag = train_tagged_words):\n",
    "    tag_list = [(word, tag) for word, tag in train_bag if tag == itag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [word for word, tag in tag_list if word == iword]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 27474)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_given_tag('Carolina', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [tag for word, tag in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032, 9339)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN', 'ADP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "class Viterbi:\n",
    "    def __init__(self, train_tagged_words):\n",
    "        self.__train_words = [word for word, tags in train_tagged_words]\n",
    "        self.__train_tags = sorted(list(set([tag for word, tag in train_tagged_words])))\n",
    "    \n",
    "        v = len(self.__train_words)\n",
    "        t = len(self.__train_tags)\n",
    "    \n",
    "        transition_p = np.zeros((t, t), dtype='float32')\n",
    "        for i, t1 in enumerate(self.__train_tags):\n",
    "            for j, t2 in enumerate(self.__train_tags):\n",
    "                counts = t2_given_t1(t2, t1)\n",
    "                transition_p[i, j] = counts[0] / counts[1]\n",
    "        self.__transition_p_df = pd.DataFrame(transition_p, columns=self.__train_tags, index=self.__train_tags)\n",
    "            \n",
    "        self.__emission_p_df = pd.DataFrame(index=self.__train_tags)\n",
    "        \n",
    "    def tag(self, words, rule_based_tagger=None, laplace_smoothing=False):\n",
    "        state = []\n",
    "        \n",
    "        # update cache for emission probabilities\n",
    "        for word in words:\n",
    "            # emission probabilities for the word is already cached\n",
    "            if word in self.__emission_p_df.columns:\n",
    "                continue\n",
    "                \n",
    "            for tag in self.__train_tags:\n",
    "                counts = word_given_tag(word, tag)\n",
    "                self.__emission_p_df.loc[tag, word] = counts[0] / counts[1]\n",
    "\n",
    "        for key, word in enumerate(words):\n",
    "            #initialise list of probability column for a given observation\n",
    "            p = [] \n",
    "\n",
    "            for tag in self.__train_tags:                \n",
    "                if key == 0:\n",
    "                    transition_p = self.__transition_p_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = self.__transition_p_df.loc[state[-1], tag]\n",
    "\n",
    "                emission_p = 0\n",
    "                # cached emission probailities for the word\n",
    "                emission_p = self.__emission_p_df.loc[tag, word]\n",
    "\n",
    "                state_probability = emission_p * transition_p    \n",
    "                \n",
    "                # unknown word handling - Approach 2 - laplace smoothing\n",
    "                if laplace_smoothing and word not in self.__train_words:\n",
    "                    state_probability = transition_p\n",
    "\n",
    "                p.append(state_probability)\n",
    "\n",
    "            pmax = max(p)\n",
    "            \n",
    "            # getting state for which probability is maximum\n",
    "            state_max = self.__train_tags[p.index(pmax)]\n",
    "\n",
    "            # unknown word handling - Approach 1 - rule based tagger\n",
    "            if word not in self.__train_words:\n",
    "                if rule_based_tagger:\n",
    "                    state_max = rule_based_tagger.tag([word])[0][1]\n",
    "             \n",
    "            state.append(state_max)\n",
    "\n",
    "        return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi = Viterbi(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Carolina', 'NOUN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi.tag(['Carolina'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5008"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('While', 'ADP'), ('the', 'DET')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['While', 'the']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = [word for word, tag in test_tagged_words]\n",
    "test_words[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = viterbi.tag(test_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = f'Tagging Complete. Time taken to tag test seq: {difference}secs.'\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tagged_seq, test_tagged_words):\n",
    "    predicted_tags = [tag for word, tag in tagged_seq]\n",
    "    actual_tags = [tag for word, tag in test_tagged_words]\n",
    "    # accuracy\n",
    "    correctly_tagged = [predicted_tag for predicted_tag, actual_tag in zip(predicted_tags, actual_tags) \n",
    "                                    if predicted_tag == actual_tag] \n",
    "    accuracy = len(correctly_tagged) / len(actual_tags)\n",
    "    return round(100 * accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy of vanilla viterbi POS tagger: {accuracy(tagged_seq, test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unknown_tagged_incorrectly(tagged_seq, test_tagged_words, train_tagged_words):\n",
    "    train_words = [word for (word, _) in train_tagged_words]\n",
    "    print('Tags not in train set')\n",
    "    return pd.DataFrame([(word, tag, actual_tag) \n",
    "            for (word, tag), (_, actual_tag) in zip(tagged_seq, test_tagged_words) \n",
    "            if word not in train_words and tag != actual_tag],\n",
    "            columns=['word', 'tag', 'actual_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets figure out the unknown words\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(tagged_seq, test_tagged_words, train_tagged_words)\n",
    "unknown_tagged_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unknown_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if the unknown words have same tags\n",
    "unknown_tagged_words['tag'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend Viterbi with Rule-based tagger\n",
    "In here, the vanilla viterbi is extended by rule based taggers, where if a particular word in not found in train words, we will use the tag given by the rule based tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets identify the mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(tagged_seq, test_tagged_words, train_tagged_words)\n",
    "unknown_tagged_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a rule based tagger\n",
    "patterns = [\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NOUN')                  # nouns\n",
    "]\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_based_tagged_seq = viterbi.tag(test_words, rule_based_tagger)\n",
    "print(f'Accuracy of rule based viterbi POS tagger: {accuracy(rule_based_tagged_seq, test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a rule based tagger - add NUM for number matches\n",
    "patterns = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NOUN')                  # nouns\n",
    "]\n",
    "rule_based_tagged_seq = viterbi.tag(test_words, rule_based_tagger)\n",
    "print(f'Accuracy of rule based viterbi POS tagger: {accuracy(rule_based_tagged_seq, test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets identify any other mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(rule_based_tagged_seq, test_tagged_words, train_tagged_words)\n",
    "unknown_tagged_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a rule based tagger - ADJ for gerund\n",
    "patterns = [\n",
    "    (r'.*ing$', 'ADJ'),              # gerund\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NOUN')                  # nouns\n",
    "]\n",
    "rule_based_tagged_seq = viterbi.tag(test_words, rule_based_tagger)\n",
    "print(f'Accuracy of rule based viterbi POS tagger: {accuracy(rule_based_tagged_seq, test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets identify any other mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(rule_based_tagged_seq, test_tagged_words, train_tagged_words)\n",
    "unknown_tagged_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a rule based tagger - ADJ for 'ous'\n",
    "patterns = [\n",
    "    (r'(.*ing|.*ous)$', 'ADJ'),\n",
    "    (r'.*ed$', 'VERB'),               # past tense\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NOUN')                  # nouns\n",
    "]\n",
    "rule_based_tagged_seq = viterbi.tag(test_words, rule_based_tagger)\n",
    "print(f'Accuracy of rule based viterbi POS tagger: {accuracy(rule_based_tagged_seq, test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets identify any other mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(rule_based_tagged_seq, test_tagged_words, train_tagged_words)\n",
    "unknown_tagged_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply unigram tagger\n",
    "# lexicon backed up by the rule-based tagger\n",
    "lexicon_tagger = nltk.BigramTagger(train_set, backoff=rule_based_tagger)\n",
    "rule_based_tagged_seq = viterbi.tag(test_words, lexicon_tagger)\n",
    "print(f'Accuracy of rule based viterbi POS tagger: {accuracy(rule_based_tagged_seq, test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend Viterbi with Probabilistic method - Laplace smooting\n",
    "In laplace smooting, for the unknown words, we will consider only the transition probabilities to determine the tag in viterbi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tagged_seq = viterbi.tag(test_words, laplace_smoothing=True)\n",
    "print(f'Accuracy of probalistic based viterbi POS tagger: {accuracy(prob_tagged_seq, test_tagged_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Accuracy'])\n",
    "results.loc['Vanilla Viterbi'] = accuracy(tagged_seq, test_tagged_words)\n",
    "results.loc['Viterbi with rule based tagger'] = accuracy(rule_based_tagged_seq, test_tagged_words)\n",
    "results.loc['Vanilla with laplace smooting'] = accuracy(prob_tagged_seq, test_tagged_words)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cases which were incorrectly tagged by original POS tagger and got corrected by the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrectly tagged words from tagged_seq which were corrected in merged_tag_seq\n",
    "corrected_tags = \\\n",
    "[(word, viterbi_tag, viterbi_extend_tag, actual_tag)\n",
    " for (word, actual_tag), (_, viterbi_tag), (_, viterbi_extend_tag) in \n",
    " zip(test_tagged_words, tagged_seq, prob_tagged_seq)\n",
    " if (viterbi_tag != actual_tag) and (viterbi_extend_tag == actual_tag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(corrected_tags,\n",
    "             columns=[\"word\", \"vanilla viterbi tag\", \"viterbi-lapace tag\", \"acutal tag\"]\n",
    "            ).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating tags on test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Test_sentences.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "with open(file_path) as f:\n",
    "    test_sentences = f.read().split('\\n')\n",
    "# test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_test_seq_vanilla = []\n",
    "for sent in test_sentences:\n",
    "    tagged_test_seq_vanilla.append(viterbi.tag(sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_test_seq = []\n",
    "for sent in test_sentences:\n",
    "    tagged_test_seq.append(viterbi.tag(sent.split(), laplace_smoothing=True))\n",
    "#     tagged_test_seq.append(viterbi.tag(sent.split(), lexicon_tagger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_word_tags = [(word, tag) for tups in tagged_test_seq_vanilla for word, tag in tups]\n",
    "t2_word_tags = [(word, tag) for tups in tagged_test_seq for word, tag in tups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_tags = [(word, tag1, tag2) for (word, tag1), (_, tag2) in zip(t1_word_tags, t2_word_tags) if tag1 != tag2]\n",
    "pd.DataFrame(diff_tags,\n",
    "             columns=['word', 'vanilla viterbi tag', 'extended viterbi tag']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tag_sentence(sent_tup):\n",
    "    for tup in sent_tup:\n",
    "        print(f'{tup[0]}/{tup[1]}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tag_sentence(tagged_test_seq_vanilla[0])\n",
    "print_tag_sentence(tagged_test_seq_vanilla[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tag_sentence(tagged_test_seq[0])\n",
    "print_tag_sentence(tagged_test_seq[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the result, following thress results got corrected.\n",
    "\n",
    "- Case 1:  \n",
    "Vanilla Viterbi &nbsp;&nbsp;&nbsp; : <kbd>**Android/.** is/VERB a/DET mobile/ADJ operating/NOUN system/NOUN developed/VERB by/ADP Google./.</kbd>   \n",
    "Extended Viterbi: <kbd>**Android/NOUN** is/VERB a/DET mobile/ADJ operating/NOUN system/NOUN developed/VERB by/ADP Google./NOUN</kbd>\n",
    "\n",
    "- Case 2:  \n",
    "Vanilla Viterbi &nbsp;&nbsp;&nbsp; : <kbd>Android/. has/VERB been/VERB the/DET best-selling/ADJ **OS/.** worldwide/. on/ADP smartphones/. since/ADP 2011/. and/CONJ on/ADP tablets/NOUN since/ADP 2013./.</kbd>   \n",
    "Extended Viterbi: <kbd>Android/NOUN has/VERB been/VERB the/DET best-selling/ADJ **OS/NOUN** worldwide/NOUN on/ADP smartphones/NOUN since/ADP 2011/NOUN and/CONJ on/ADP tablets/NOUN since/ADP 2013./NOUN</kbd>  \n",
    "\n",
    "- Case 3:  \n",
    "Vanilla Viterbi &nbsp;&nbsp;&nbsp; : <kbd>Android/. has/VERB been/VERB the/DET best-selling/ADJ OS/. worldwide/. on/ADP **smartphones/.** since/ADP 2011/. and/CONJ on/ADP tablets/NOUN since/ADP 2013./.</kbd>   \n",
    "Extended Viterbi: <kbd>Android/NOUN has/VERB been/VERB the/DET best-selling/ADJ OS/NOUN worldwide/NOUN on/ADP **smartphones/NOUN** since/ADP 2011/NOUN and/CONJ on/ADP tablets/NOUN since/ADP 2013./NOUN</kbd>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
