{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/shakeeb/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(nltk_data, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Paul', 'NOUN'),\n",
       " ('Sandifer', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('director', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('testing', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('South', 'NOUN'),\n",
       " ('Carolina', 'NOUN'),\n",
       " ('department', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('education', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('says', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Cannell', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('allegations', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('cheating', 'NOUN'),\n",
       " ('``', '.'),\n",
       " ('are', 'VERB'),\n",
       " ('purely', 'ADV'),\n",
       " ('without', 'ADP'),\n",
       " ('foundation', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('based', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('unfair', 'ADJ'),\n",
       " ('inferences', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95780"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tagged words\n",
    "tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12084"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tokens\n",
    "tokens = [word for word, tags in tagged_words]\n",
    "v = len(set(tokens))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tags\n",
    "tags = set([tag for word, tag in tagged_words])\n",
    "t = len(tags)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(iword, itag, train_bag = tagged_words):\n",
    "    tag_list = [(word, tag) for word, tag in train_bag if tag == itag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [word for word, tag in tag_list if word == iword]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 27502)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_given_tag('Carolina', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag = tagged_words):\n",
    "    tags = [tag for word, tag in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3029, 9378)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN', 'ADP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix = np.zeros((t, t), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADP</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>.</th>\n",
       "      <th>DET</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.322990</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.063020</td>\n",
       "      <td>0.105993</td>\n",
       "      <td>0.069098</td>\n",
       "      <td>0.040094</td>\n",
       "      <td>0.323523</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.033803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.176169</td>\n",
       "      <td>0.265908</td>\n",
       "      <td>0.146389</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>0.043924</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.239401</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>0.029016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.090592</td>\n",
       "      <td>0.110259</td>\n",
       "      <td>0.169725</td>\n",
       "      <td>0.081843</td>\n",
       "      <td>0.031436</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.064576</td>\n",
       "      <td>0.035695</td>\n",
       "      <td>0.034533</td>\n",
       "      <td>0.134417</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.219048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.030754</td>\n",
       "      <td>0.343915</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.127646</td>\n",
       "      <td>0.014550</td>\n",
       "      <td>0.136243</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.023479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.021207</td>\n",
       "      <td>0.246656</td>\n",
       "      <td>0.400653</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>0.085155</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>0.042088</td>\n",
       "      <td>0.101142</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.013051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADP      NOUN      VERB       ADV       PRT       NUM       ADJ  \\\n",
       "ADP   0.016848  0.322990  0.008424  0.014075  0.001280  0.063020  0.105993   \n",
       "NOUN  0.176169  0.265908  0.146389  0.017162  0.043924  0.009599  0.011854   \n",
       "VERB  0.090592  0.110259  0.169725  0.081843  0.031436  0.022687  0.064576   \n",
       "ADV   0.120370  0.030754  0.343915  0.080357  0.013889  0.032738  0.127646   \n",
       "PRT   0.021207  0.246656  0.400653  0.010440  0.001958  0.056770  0.085155   \n",
       "\n",
       "          PRON         .       DET      CONJ         X  \n",
       "ADP   0.069098  0.040094  0.323523  0.000853  0.033803  \n",
       "NOUN  0.004872  0.239401  0.013235  0.042470  0.029016  \n",
       "VERB  0.035695  0.034533  0.134417  0.005188  0.219048  \n",
       "ADV   0.014550  0.136243  0.069444  0.006614  0.023479  \n",
       "PRT   0.018597  0.042088  0.101142  0.002284  0.013051  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words):\n",
    "    state = []\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in tags:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = list(tags)[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Carolina', 'NOUN')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Viterbi(['Carolina'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4896"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806.738972902298"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(f'Time taken to tag test seq: {difference}secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_run_base = [tag for word, tag in test_tagged_words]\n",
    "# accuracy\n",
    "correctly_tagged = [predicted_tag for predicted_tag, actual_tag in zip(tagged_seq, test_run_base) \n",
    "                                if predicted_tag == actual_tag] \n",
    "accuracy = len(correctly_tagged)/len(tagged_seq)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
