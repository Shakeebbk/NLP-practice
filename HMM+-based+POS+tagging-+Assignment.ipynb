{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('treebank')\n",
    "# nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(nltk_data, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('promised', 'VERB'),\n",
       " ('stiffer', 'ADJ'),\n",
       " ('fines', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('though', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('size', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('penalties', 'NOUN'),\n",
       " ('sought', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('OSHA', 'NOUN'),\n",
       " ('have', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('rising', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('recent', 'ADJ'),\n",
       " ('years', 'NOUN'),\n",
       " ('even', 'ADV'),\n",
       " ('before', 'ADP'),\n",
       " ('he', 'PRON'),\n",
       " ('took', 'VERB'),\n",
       " ('office', 'NOUN'),\n",
       " ('this', 'DET'),\n",
       " ('year', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95668"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12097"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tokens\n",
    "train_words = [word for word, tags in train_tagged_words]\n",
    "v = len(set(train_words))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tags\n",
    "train_tags = set([tag for word, tag in train_tagged_words])\n",
    "t = len(tags)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(iword, itag, train_bag = train_tagged_words):\n",
    "    tag_list = [(word, tag) for word, tag in train_bag if tag == itag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [word for word, tag in tag_list if word == iword]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 27474)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_given_tag('Carolina', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [tag for word, tag in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032, 9339)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN', 'ADP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix = np.zeros((t, t), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PRT</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>DET</th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.033837</td>\n",
       "      <td>0.061141</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.324660</td>\n",
       "      <td>0.069172</td>\n",
       "      <td>0.323803</td>\n",
       "      <td>0.040261</td>\n",
       "      <td>0.105793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.116550</td>\n",
       "      <td>0.078921</td>\n",
       "      <td>0.346653</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.022977</td>\n",
       "      <td>0.031635</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.031635</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.068931</td>\n",
       "      <td>0.138528</td>\n",
       "      <td>0.128538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.090874</td>\n",
       "      <td>0.081468</td>\n",
       "      <td>0.168688</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.216807</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.111085</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>0.135728</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>0.064599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.019544</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.400326</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.246254</td>\n",
       "      <td>0.018241</td>\n",
       "      <td>0.101629</td>\n",
       "      <td>0.043648</td>\n",
       "      <td>0.085993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.143538</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0.203942</td>\n",
       "      <td>0.185344</td>\n",
       "      <td>0.074869</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.062947</td>\n",
       "      <td>0.055158</td>\n",
       "      <td>0.055317</td>\n",
       "      <td>0.163726</td>\n",
       "      <td>0.016532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADP       ADV      VERB       PRT         X       NUM      CONJ  \\\n",
       "ADP   0.017025  0.013813  0.008352  0.001285  0.033837  0.061141  0.000857   \n",
       "ADV   0.116550  0.078921  0.346653  0.013986  0.022977  0.031635  0.006327   \n",
       "VERB  0.090874  0.081468  0.168688  0.031250  0.216807  0.022621  0.005442   \n",
       "PRT   0.019544  0.010098  0.400326  0.001954  0.014007  0.056026  0.002280   \n",
       "X     0.143538  0.025433  0.203942  0.185344  0.074869  0.002702  0.010491   \n",
       "\n",
       "          NOUN      PRON       DET         .       ADJ  \n",
       "ADP   0.324660  0.069172  0.323803  0.040261  0.105793  \n",
       "ADV   0.031635  0.015318  0.068931  0.138528  0.128538  \n",
       "VERB  0.111085  0.036070  0.135728  0.035370  0.064599  \n",
       "PRT   0.246254  0.018241  0.101629  0.043648  0.085993  \n",
       "X     0.062947  0.055158  0.055317  0.163726  0.016532  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(train_tags), index=list(train_tags))\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, tags_df = tags_df):\n",
    "    state = []\n",
    "    tags_list = tags_df.index\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in tags_list:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = tags_list[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Carolina', 'NOUN')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Viterbi(['Carolina'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5008"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('While', 'ADP'), ('the', 'DET')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['While', 'the']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = [word for word, tag in test_tagged_words]\n",
    "test_words[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def whatsapp(msg):\n",
    "    os.system(f'/home/shakeeb/Documents/twilio-whatsapp/run.sh \"{msg}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete. Time taken to tag test seq: 1354.3533408641815secs\n"
     ]
    }
   ],
   "source": [
    "msg = f'Training Complete. Time taken to tag test seq: {difference}secs'\n",
    "print(msg)\n",
    "whatsapp(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('While', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('new', 'ADJ'),\n",
       " ('proposal', 'NOUN'),\n",
       " ('might', 'VERB'),\n",
       " ('appeal', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('the', 'DET'),\n",
       " ('dirtiest', 'ADJ'),\n",
       " ('utilities', 'NOUN')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_seq[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tagged_seq, test_tagged_words):\n",
    "    predicted_tags = [tag for word, tag in tagged_seq]\n",
    "    actual_tags = [tag for word, tag in test_tagged_words]\n",
    "    # accuracy\n",
    "    correctly_tagged = [predicted_tag for predicted_tag, actual_tag in zip(predicted_tags, actual_tags) \n",
    "                                    if predicted_tag == actual_tag] \n",
    "    accuracy = len(correctly_tagged)/len(actual_tags)\n",
    "    return round(100*accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071485623003195"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(tagged_seq, test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrect_tagged(tagged_seq, test_tagged_words):\n",
    "    actual_tags = [tag for word, tag in test_tagged_words]\n",
    "    return [(word, predicted_tag, actual_tag) for (word, predicted_tag), actual_tag in zip(tagged_seq, actual_tags) \n",
    "                                if predicted_tag != actual_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('appeal', 'NOUN', 'VERB'),\n",
       " ('cleanup', 'ADP', 'NOUN'),\n",
       " ('burn', 'ADP', 'VERB'),\n",
       " ('cleaner-burning', 'ADP', 'ADJ'),\n",
       " ('fuels', 'ADP', 'NOUN'),\n",
       " ('elaborate', 'VERB', 'ADJ'),\n",
       " ('*-94', 'ADP', 'X'),\n",
       " ('that', 'ADP', 'DET'),\n",
       " ('*T*-117', 'ADP', 'X'),\n",
       " ('uptick', 'NOUN', 'VERB')]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrectly_tagged = get_incorrect_tagged(tagged_seq, test_tagged_words)\n",
    "incorrectly_tagged[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unknown_tagged_incorrectly(tagged_seq, test_tagged_words, train_words):\n",
    "    print('Tags not in train set\\nword - tag - actual_tag')\n",
    "    return [(word, tag, actual_tag) \n",
    "            for (word, tag), (_, actual_tag) in zip(tagged_seq, test_tagged_words) \n",
    "            if word not in train_words and tag != actual_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags not in train set\n",
      "word - tag - actual_tag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cleanup', 'ADP', 'NOUN'),\n",
       " ('burn', 'ADP', 'VERB'),\n",
       " ('cleaner-burning', 'ADP', 'ADJ'),\n",
       " ('fuels', 'ADP', 'NOUN'),\n",
       " ('*-94', 'ADP', 'X'),\n",
       " ('*T*-117', 'ADP', 'X'),\n",
       " ('Jennison', 'ADP', 'NOUN'),\n",
       " ('bell-ringing', 'ADP', 'ADJ'),\n",
       " ('Ancient', 'ADP', 'NOUN'),\n",
       " ('Youths', 'ADP', 'NOUN')]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets figure out the unknown words\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(tagged_seq, test_tagged_words, train_words)\n",
    "unknown_tagged_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unknown_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADP']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the unknown words have same tags\n",
    "tags = [tag for word, tag in unknown_tagged_words]\n",
    "list(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a rule based tagger\n",
    "patterns = [\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NN')                    # nouns\n",
    "]\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge viterbi and rule based tagger\n",
    "def extended_viterbi(viterbi_tagged_seq, new_tagger, test_tagged_words = test_tagged_words):\n",
    "    new_tagged = new_tagger.tag(test_words)\n",
    "    \n",
    "    merged_tag_seq = []\n",
    "    i = 0\n",
    "    for (word, viterbi_tag), (_, rule_tag) in zip(tagged_seq, new_tagged):\n",
    "        if word in unknown_words:\n",
    "            merged_tag_seq.append((word, rule_tag))\n",
    "        else:\n",
    "            merged_tag_seq.append((word, viterbi_tag))\n",
    "            \n",
    "    print(f'Accuracy of new tagger:              {accuracy(new_tagged, test_tagged_words)}')\n",
    "    print(f'Accuracy of original viterbi tagger: {accuracy(viterbi_tagged_seq, test_tagged_words)}')    \n",
    "    print(f'Accuracy of extended viterbi tagger: {accuracy(merged_tag_seq, test_tagged_words)}')\n",
    "\n",
    "    return merged_tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of new tagger:              38.1\n",
      "Accuracy of original viterbi tagger: 90.71\n",
      "Accuracy of extended viterbi tagger: 95.01\n"
     ]
    }
   ],
   "source": [
    "merged_tag_seq = extended_viterbi(tagged_seq, rule_based_tagger, test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags not in train set\n",
      "word - tag - actual_tag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('burn', 'NOUN', 'VERB'),\n",
       " ('male-only', 'NOUN', 'ADJ'),\n",
       " ('sole', 'NOUN', 'ADJ'),\n",
       " ('complaining', 'ADJ', 'VERB'),\n",
       " ('opposite', 'NOUN', 'ADJ'),\n",
       " ('loathsome', 'NOUN', 'ADJ'),\n",
       " ('propelling', 'ADJ', 'VERB'),\n",
       " ('serves', 'NOUN', 'VERB'),\n",
       " ('sitting', 'ADJ', 'VERB'),\n",
       " ('apologize', 'NOUN', 'VERB')]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets identify any other mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(merged_tag_seq, test_tagged_words, train_words)\n",
    "unknown_tagged_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of new tagger:              7.73\n",
      "Accuracy of original viterbi tagger: 90.71\n",
      "Accuracy of extended viterbi tagger: 91.71\n"
     ]
    }
   ],
   "source": [
    "# build a rule based tagger\n",
    "patterns = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NN')                    # nouns\n",
    "]\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "merged_tag_seq = extended_viterbi(tagged_seq, rule_based_tagger, test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags not in train set\n",
      "word - tag - actual_tag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cleanup', 'NN', 'NOUN'),\n",
       " ('burn', 'NN', 'VERB'),\n",
       " ('cleaner-burning', 'NN', 'ADJ'),\n",
       " ('fuels', 'NN', 'NOUN'),\n",
       " ('Jennison', 'NN', 'NOUN'),\n",
       " ('bell-ringing', 'NN', 'ADJ'),\n",
       " ('Ancient', 'NN', 'NOUN'),\n",
       " ('Youths', 'NN', 'NOUN'),\n",
       " ('male-only', 'NN', 'ADJ'),\n",
       " ('galling', 'NN', 'ADJ')]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets identify any other mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(merged_tag_seq, test_tagged_words, train_words)\n",
    "unknown_tagged_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of new tagger:              34.94\n",
      "Accuracy of original viterbi tagger: 90.71\n",
      "Accuracy of extended viterbi tagger: 94.57\n"
     ]
    }
   ],
   "source": [
    "# build a rule based tagger\n",
    "patterns = [\n",
    "    (r'.*ing$', 'ADJ'),              # gerund\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NOUN')                    # nouns\n",
    "]\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "merged_tag_seq = extended_viterbi(tagged_seq, rule_based_tagger, test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags not in train set\n",
      "word - tag - actual_tag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('burn', 'NOUN', 'VERB'),\n",
       " ('male-only', 'NOUN', 'ADJ'),\n",
       " ('sole', 'NOUN', 'ADJ'),\n",
       " ('complaining', 'ADJ', 'VERB'),\n",
       " ('nullified', 'NOUN', 'VERB'),\n",
       " ('opposite', 'NOUN', 'ADJ'),\n",
       " ('loathsome', 'NOUN', 'ADJ'),\n",
       " ('cautious', 'NOUN', 'ADJ'),\n",
       " ('propelling', 'ADJ', 'VERB'),\n",
       " ('serves', 'NOUN', 'VERB')]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets identify any other mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(merged_tag_seq, test_tagged_words, train_words)\n",
    "unknown_tagged_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of new tagger:              38.1\n",
      "Accuracy of original viterbi tagger: 90.71\n",
      "Accuracy of extended viterbi tagger: 95.01\n"
     ]
    }
   ],
   "source": [
    "# build a rule based tagger\n",
    "patterns = [\n",
    "    (r'(.*ing|.*ous)$', 'ADJ'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'\\*+', 'X'),                   # if there are * in the words, mark it X\n",
    "    (r'.*', 'NOUN')                    # nouns\n",
    "]\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "merged_tag_seq = extended_viterbi(tagged_seq, rule_based_tagger, test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags not in train set\n",
      "word - tag - actual_tag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('burn', 'NOUN', 'VERB'),\n",
       " ('male-only', 'NOUN', 'ADJ'),\n",
       " ('sole', 'NOUN', 'ADJ'),\n",
       " ('complaining', 'ADJ', 'VERB'),\n",
       " ('opposite', 'NOUN', 'ADJ'),\n",
       " ('loathsome', 'NOUN', 'ADJ'),\n",
       " ('propelling', 'ADJ', 'VERB'),\n",
       " ('serves', 'NOUN', 'VERB'),\n",
       " ('sitting', 'ADJ', 'VERB'),\n",
       " ('apologize', 'NOUN', 'VERB')]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets identify any other mismatches\n",
    "unknown_tagged_words = get_unknown_tagged_incorrectly(merged_tag_seq, test_tagged_words, train_words)\n",
    "unknown_tagged_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply unigram and bigram tagger\n",
    "# lexicon backed up by the rule-based tagger\n",
    "lexicon_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_tagger)\n",
    "\n",
    "#lexicon based bigram tagger\n",
    "bigram_tagger = nltk.BigramTagger(train_set, backoff=lexicon_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of new tagger:              95.21\n",
      "Accuracy of original viterbi tagger: 90.71\n",
      "Accuracy of extended viterbi tagger: 95.01\n"
     ]
    }
   ],
   "source": [
    "merged_tag_seq = extended_viterbi(tagged_seq, bigram_tagger, test_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrectly tagged words from tagged_seq which were corrected in merged_tag_seq\n",
    "corrected_tags = \\\n",
    "[(word, viterbi_tag, viterbi_extend_tag, actual_tag)\n",
    " for (word, actual_tag), (_, viterbi_tag), (_, viterbi_extend_tag) in \n",
    " zip(test_tagged_words, tagged_seq, merged_tag_seq)\n",
    " if (viterbi_tag != actual_tag) and (viterbi_extend_tag == actual_tag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags corrected with extended viterbi tagger\n",
      "--------------------------------------------------------------------------\n",
      "Word            | vanilla viterbi tag | extended viterbi tag | acutal tag\n",
      "----------------|---------------------|----------------------|------------\n",
      "cleanup         | ADP                 | NOUN                 | NOUN\n",
      "cleaner-burning | ADP                 | ADJ                  | ADJ\n",
      "fuels           | ADP                 | NOUN                 | NOUN\n",
      "*-94            | ADP                 | X                    | X\n",
      "*T*-117         | ADP                 | X                    | X\n",
      "Jennison        | ADP                 | NOUN                 | NOUN\n",
      "bell-ringing    | ADP                 | ADJ                  | ADJ\n",
      "Ancient         | ADP                 | NOUN                 | NOUN\n",
      "Youths          | ADP                 | NOUN                 | NOUN\n",
      "1637            | ADP                 | NUM                  | NUM\n"
     ]
    }
   ],
   "source": [
    "print('Tags corrected with extended viterbi tagger')\n",
    "print(f'--------------------------------------------------------------------------')\n",
    "print(f'{\"Word\":<15s} | {\"vanilla viterbi tag\"} | extended viterbi tag | acutal tag')\n",
    "print(f'{\"-\"*16}|{\"-\"*21}|{\"-\"*22}|{\"-\"*12}')\n",
    "for word, viterbi_tag, viterbi_ex_tag, actual_tag in corrected_tags[0:10]:\n",
    "    print(f'{word:<15s} | {viterbi_tag:19s} | {viterbi_ex_tag:20s} | {actual_tag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
